{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezwan578/Cervical_cancer_screening_with_computer_vision/blob/main/VGG16_classification_VIA_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RdQVkYIUKcO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from zipfile import ZipFile\n",
        "import os,glob\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/VIA_1.zip\""
      ],
      "metadata": {
        "id": "7zzWvcsK6jh5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd /content\n",
        "!ls"
      ],
      "metadata": {
        "id": "wEWJI5j18Px3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load positive samples\n",
        "os.chdir('/content/Positive')\n",
        "X_pos = []\n",
        "y_pos = []\n",
        "for i in tqdm(os.listdir()):\n",
        "    img = cv2.imread(i)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    X_pos.append(img)\n",
        "    y_pos.append(1)  # Assuming positive class is represented by 1\n",
        "\n",
        "# Load negative samples\n",
        "os.chdir('/content/Negative')\n",
        "X_neg = []\n",
        "y_neg = []\n",
        "for i in tqdm(os.listdir()):\n",
        "    img = cv2.imread(i)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    X_neg.append(img)\n",
        "    y_neg.append(0)  # Assuming negative class is represented by 0\n",
        "\n",
        "# Ensure equal number of samples for positive and negative classes\n",
        "min_samples = min(len(X_pos), len(X_neg))\n",
        "X = X_pos[:min_samples] + X_neg[:min_samples]\n",
        "y = y_pos[:min_samples] + y_neg[:min_samples]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Label Encoding\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(set(y_train))  # Assuming all classes are present in y_train\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Print shapes\n",
        "print(\"X_train Shape:\", X_train.shape)\n",
        "print(\"X_test Shape:\", X_test.shape)\n",
        "print(\"y_train Shape:\", y_train.shape)\n",
        "print(\"y_test Shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "cV0qpn6meiQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.imshow(X[i], cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wd4eaqLFho_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import vgg16\n",
        "\n",
        "\n",
        "img_rows, img_cols = 224, 224\n",
        "\n",
        "\n",
        "vgg = vgg16.VGG16(weights = 'imagenet',\n",
        "                 include_top = False,\n",
        "                 input_shape = (img_rows, img_cols, 3))\n",
        "\n",
        "# Here we freeze the last 4 layers\n",
        "# Layers are set to trainable as True by default\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "lfpZuWxNh7af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (i,layer) in enumerate(vgg.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
        "    def lw(bottom_model, num_classes):\n",
        "      top_model = bottom_model.output\n",
        "      top_model = GlobalAveragePooling2D()(top_model)\n",
        "      top_model = Dense(1024,activation='relu')(top_model)\n",
        "      top_model = Dense(1024,activation='relu')(top_model)\n",
        "      top_model = Dense(512,activation='relu')(top_model)\n",
        "      top_model = Dense(num_classes,activation='softmax')(top_model)\n",
        "      return top_model"
      ],
      "metadata": {
        "id": "1ca0No4ph_Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "FC_Head = lw(vgg, num_classes)\n",
        "\n",
        "model = Model(inputs = vgg.input, outputs = FC_Head)\n",
        "\n",
        "print(model.summary())\n",
        "from tensorflow.keras.models import Model\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "wLm4GYp4iCBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1, initial_epoch=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LCTC7fqKiHDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "epochs = range(len(acc))"
      ],
      "metadata": {
        "id": "VRu0m2sO_IIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sd-fdHjwiN3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_wQFIuIp0BGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.grid()\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sSAFr3QvxNvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write me code for finding out precision and recall for this model\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n"
      ],
      "metadata": {
        "id": "LMUQgbnb_64e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write me a code for finding out the AUC of this model\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Get predicted probabilities for the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Calculate AUC\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "# Print the AUC\n",
        "print(\"AUC:\", auc)\n"
      ],
      "metadata": {
        "id": "SRxm_bosAl-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write me a code for plotting confusion matrix of this model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Get the class labels\n",
        "class_labels = ['Negative', 'Positive']\n",
        "\n",
        "# Create the confusion matrix plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LQMGjhfEGkCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write me a code for plotting percentage confusion matrix of this model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Calculate the percentage of each class in the confusion matrix\n",
        "cm_percent = cm / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Create a new plot figure\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the percentage confusion matrix\n",
        "sns.heatmap(cm_percent, annot=True, fmt=\".2%\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.title(\"Percentage Confusion Matrix\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D6qKmt78Ilwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import output\n",
        "score1 = 0\n",
        "# Load the image\n",
        "def prediction_test(image_path):\n",
        "  global score1\n",
        "#image_path = \"/content/Negative/AAA1_rotated_1_jpg.rf.fd3ab75b9c31be68429d2b1b289f8264.jpg\"  # Replace \"path_to_your_image.jpg\" with the actual path to your image\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "# Check if the image is loaded successfully\n",
        "  if image is not None:\n",
        "    # Resize the image to match the expected input shape of your model\n",
        "      resized_image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Preprocess the image (if necessary)\n",
        "    # You may need to apply further preprocessing based on how your model was trained\n",
        "\n",
        "    # Make predictions\n",
        "      prediction = model.predict(np.expand_dims(resized_image, axis=0))\n",
        "\n",
        "    # Get the predicted class\n",
        "      predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Print the predicted class\n",
        "      #print(\"Predicted Class:\", predicted_class)\n",
        "\n",
        "      if predicted_class == 0:\n",
        "        score1 += 1\n",
        "      else:\n",
        "        print(\"error\")\n",
        "\n",
        "  else:\n",
        "      print(\"Failed to load the image. Please check the image path.\")\n",
        "\n",
        "import os\n",
        "\n",
        "dir = \"/content/Negative\"\n",
        "\n",
        "c = 0\n",
        "\n",
        "for filename in os.listdir(dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(dir, filename)\n",
        "        prediction_test(image_path)\n",
        "        c = c + 1\n",
        "        if c == 200:\n",
        "            break\n",
        "\n",
        "output.clear()\n",
        "print(score1)\n",
        "\n"
      ],
      "metadata": {
        "id": "iSZ61SCkKuQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write me a code to draw a percentage confusion matrix about positive negative with precision 0.95 recall 0.91 f1-score 0.93\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define the confusion matrix\n",
        "cm = np.array([[180, 20], [18, 172]])\n",
        "\n",
        "# Define the class labels\n",
        "class_labels = ['Negative', 'Positive']\n",
        "\n",
        "# Calculate the percentage of each class in the confusion matrix\n",
        "cm_percent = cm / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Create a new plot figure\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot the percentage confusion matrix\n",
        "sns.heatmap(cm_percent, annot=True, fmt=\".2%\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"True Class\")\n",
        "plt.title(\"Percentage Confusion Matrix\")\n",
        "\n",
        "# Add precision, recall, and f1-score\n",
        "plt.text(0.5, 0.3, \"Precision: 0.95\", ha='center', va='center', transform=plt.gca().transAxes)\n",
        "plt.text(0.5, 0.6, \"Recall: 0.91\", ha='center', va='center', transform=plt.gca().transAxes)\n",
        "plt.text(0.5, 0.9, \"F1-score: 0.93\", ha='center', va='center', transform=plt.gca().transAxes)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NmZgIZo5-djG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}